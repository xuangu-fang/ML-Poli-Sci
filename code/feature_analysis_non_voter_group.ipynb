{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance analysis acroos intend-to-vote-but-final-vote groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020.0\n",
      "1948.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "# import model\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# data path\n",
    "file_path = '../data/cumulative_2022_v3_9_domain.csv'\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "column_to_variable_dict = np.load('../data/column_to_variable_dict.npy', allow_pickle=True).item()\n",
    "variable_to_column_dict = np.load('../data/variable_to_column_dict.npy', allow_pickle=True).item()\n",
    "\n",
    "value_label_dict = np.load('../data/value_labels.npy', allow_pickle=True).item()\n",
    "\n",
    "# check the \"Year\" column's max and min value\n",
    "print(data['Year'].max())\n",
    "print(data['Year'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_variable = 'Voted'\n",
    "\n",
    "'''Voted  {0.0: '0. DK; NA; no Post IW; refused to say if voted;', 1.0: '1. No, did not vote', 2.0: '2. Yes, voted'}'''\n",
    "\n",
    "data_new = data[data[target_variable].notnull()]\n",
    "\n",
    "sub_target_variable = 'Pre_election_inten_vote'\n",
    "\n",
    "'''Pre_election_inten_vote  {0.0: '0. DK (1964 only); NA; no Pre IW; DK/NA/RF (1952', 1.0: '1. Democratic candidate (with or without qualifications,', 2.0: '2. Republican candidate (with or without qualifications,', 3.0: '3. Undecided; DK (except 1964)', 4.0: \"4. R does not intend to vote (incl. 'no, qualified' if\", 9.0: '9. Other candidate'}\n",
    "'''\n",
    "\n",
    "\n",
    "# the total valid number of samples, who intend to vote for Democratic candidate or Republican candidate\n",
    "\n",
    "\n",
    "\n",
    "data_new = data_new[(data_new[sub_target_variable]== 1) | (data_new[sub_target_variable] == 2) | (data_new[sub_target_variable] == 9)   ]\n",
    "# folder_name = '../data/non-voter-feature-analysis/intent-vote/'\n",
    "\n",
    "\n",
    "\n",
    "# folder_name = '../data/non-voter-feature-analysis/all/'\n",
    "\n",
    "data_new = data_new[(data_new[\"State\"]== \"WA\")  ]\n",
    "\n",
    "folder_name = '../data/non-voter-feature-analysis/WA/intent-vote/'\n",
    "\n",
    "\n",
    "\n",
    "len(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value = utils.missing_value_analysis(data)\n",
    "\n",
    "# threshold_list = [0.2, 0.3, 0.4, 0.5]\n",
    "threshold_list = [0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "\n",
    "# must_include_list = ['urbanism']\n",
    "must_include_list = None\n",
    "\n",
    "\n",
    "# folder_name = '../data/non-voter-feature-analysis/'\n",
    "\n",
    "used_features, not_used_features, folder_name = utils.feature_filter(data, threshold_list,column_to_variable_dict, folder_name, must_include_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing value of the non-feature variable: \n",
      "Voted                      0.000000\n",
      "Registered_voted           0.000293\n",
      "Voted_party                0.001143\n",
      "Vote_Nonvote_Pres          0.000117\n",
      "Race3                      0.000059\n",
      "Race4                      0.000059\n",
      "Race7                      0.000059\n",
      "religion                   0.000059\n",
      "Year                       0.000000\n",
      "Pre_election_inten_vote    0.000000\n",
      "State                      0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# use the used features to filter out the data\n",
    "\n",
    "# set the target variable set and index variable set, these variables will not be used for training\n",
    "\n",
    "target_variable_list = ['Voted','Registered_voted','Voted_party','Vote_Nonvote_Pres']\n",
    "\n",
    "race_variable_list = ['Race3','Race4','Race7']\n",
    "\n",
    "religion_variable_list = ['religion']\n",
    "\n",
    "index_variable_list = ['Year', ]\n",
    "\n",
    "not_used_features = ['Pre_election_inten_vote']\n",
    "# not_used_features = []\n",
    "\n",
    "\n",
    "state_variable_list = ['State']\n",
    "\n",
    "non_feature_list = target_variable_list +  race_variable_list + religion_variable_list + index_variable_list + not_used_features + state_variable_list\n",
    "\n",
    "# check the missing ratio of the target variable\n",
    "print('missing value of the non-feature variable: ')\n",
    "print(data_new[non_feature_list].isnull().sum() / len(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples who not vote :  48\n",
      "number of samples who vote :  664\n",
      "number of samples who vote case DK :  0\n",
      "(712, 119)\n",
      "(712, 119)\n",
      "number of numerical features:  9\n",
      "number of categorical features:  38\n",
      "numerical features list: ['therm_ChrFundament', 'therm_hispanics', 'therm_RepParty', 'therm_DemParty', 'therm_Whites', 'therm_liberals', 'therm_conservatives', 'therm_Blacks', 'Age']\n"
     ]
    }
   ],
   "source": [
    "target_variable = 'Voted'\n",
    "\n",
    "'''Voted  {0.0: '0. DK; NA; no Post IW; refused to say if voted;', 1.0: '1. No, did not vote', 2.0: '2. Yes, voted'}'''\n",
    "\n",
    "# filter out the samples with missing value of the target variable,drop the index\n",
    "data_new = data_new[data_new[target_variable].notnull()]\n",
    "# filter out the samples with target variable value = 0, count the number of samples whose target variable value = 0, 1 or 2\n",
    "print('number of samples who not vote : ', len(data_new[data_new[target_variable] == 1]))\n",
    "print('number of samples who vote : ', len(data_new[data_new[target_variable] == 2]))\n",
    "print('number of samples who vote case DK : ', len(data_new[data_new[target_variable] == 0]))\n",
    "\n",
    "data_new = data_new[data_new[target_variable] != 0]\n",
    "data_new = data_new.reset_index(drop=True)\n",
    "print(data_new.shape)\n",
    "\n",
    "year_threshold = 1948\n",
    "\n",
    "folder_name = folder_name + '/'+ str(year_threshold)+ '/'\n",
    "\n",
    "# filter out the samples whose year > year_threshold\n",
    "data_new = data_new[data_new['Year'] > year_threshold]\n",
    "data_new = data_new.reset_index(drop=True)\n",
    "print(data_new.shape)\n",
    "\n",
    "\n",
    "numerical_feature_list, categorical_feature_list = utils.feature_type_analysis(data_new, used_features, non_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples of White:  610\n",
      "number of samples of Black:  17\n",
      "number of samples of Asian:  22\n",
      "number of samples of American_Indian:  4\n",
      "number of samples of Hispanic:  40\n",
      "number of samples of Other:  15\n",
      "number of samples of Protestant:  373\n",
      "number of samples of Catholic:  107\n",
      "number of samples of Jewish:  8\n",
      "number of samples of Other:  220\n"
     ]
    }
   ],
   "source": [
    "# slipt the group by race and religion\n",
    "\n",
    "data_race7_dict = utils.group_split_race7(data_new) \n",
    "data_religion_dict = utils.group_split_religon(data_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import permutation_importance\n",
    "# result = permutation_importance(model, X, Y, n_repeats=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 48)\n",
      "average accuracy:  0.9241701960011819\n",
      "average recall:  0.0988095238095238\n",
      "average precision:  0.19666666666666666\n",
      "average f1 score:  0.12803030303030302\n",
      "average roc auc score:  0.5418725203267188\n"
     ]
    }
   ],
   "source": [
    "utils.feature_importance_analysis(data_new, numerical_feature_list, categorical_feature_list, target_variable, value_label_dict, folder_name, group='whole-group', group_cat='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 48)\n",
      "average accuracy:  0.9344262295081966\n",
      "average recall:  0.02857142857142857\n",
      "average precision:  0.05\n",
      "average f1 score:  0.03636363636363636\n",
      "average roc auc score:  0.5090831873440569\n",
      "(17, 48)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [48], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group_cat \u001b[38;5;129;01min\u001b[39;00m data_race7_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      5\u001b[0m     data_group \u001b[38;5;241m=\u001b[39m data_race7_dict[group_cat]\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importance_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumerical_feature_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_label_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_cat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_cat\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fang/ML-Poli-Sci/code/utils.py:388\u001b[0m, in \u001b[0;36mfeature_importance_analysis\u001b[0;34m(data_group, numerical_feature_list, categorical_feature_list, target_variable, value_label_dict, folder_name, group, group_cat)\u001b[0m\n\u001b[1;32m    384\u001b[0m X_continuous_categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((X_continuous_transformed, X_categorical_transformed), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    386\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(l1_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m, max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m, solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m, penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 388\u001b[0m accuracy_list, recall_list, precision_list, f1_list, roc_auc_list, importance_list \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_continuous_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# use imbalanced learn to deal with the imbalanced data\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# accuracy_list, recall_list, precision_list, f1_list, roc_auc_list, importance_list = utils.cross_validation_imb(X_continuous_categorical, Y_target, model, k = 5)\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage accuracy: \u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(accuracy_list))\n",
      "File \u001b[0;32m~/fang/ML-Poli-Sci/code/utils.py:308\u001b[0m, in \u001b[0;36mcross_validation\u001b[0;34m(X, Y, model, k)\u001b[0m\n\u001b[1;32m    306\u001b[0m     precision_list\u001b[38;5;241m.\u001b[39mappend(precision_score(y_test, y_pred))\n\u001b[1;32m    307\u001b[0m     f1_list\u001b[38;5;241m.\u001b[39mappend(f1_score(y_test, y_pred))\n\u001b[0;32m--> 308\u001b[0m     roc_auc_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    309\u001b[0m     importance_list\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_list, recall_list, precision_list, f1_list, roc_auc_list, importance_list\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:640\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    639\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    649\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    650\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    654\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:382\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m     )\n\u001b[1;32m    387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "\n",
    "group = 'race'\n",
    "\n",
    "for group_cat in data_race7_dict.keys():\n",
    "\n",
    "    data_group = data_race7_dict[group_cat]\n",
    "\n",
    "    utils.feature_importance_analysis(data_group, numerical_feature_list, categorical_feature_list, target_variable, value_label_dict, folder_name, group=group, group_cat=group_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(373, 48)\n",
      "average accuracy:  0.9141981981981981\n",
      "average recall:  0.02857142857142857\n",
      "average precision:  0.2\n",
      "average f1 score:  0.05\n",
      "average roc auc score:  0.5043029675638371\n",
      "(107, 48)\n",
      "average accuracy:  0.8874458874458874\n",
      "average recall:  0.0\n",
      "average precision:  0.0\n",
      "average f1 score:  0.0\n",
      "average roc auc score:  0.48473684210526313\n",
      "(8, 48)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group_cat \u001b[38;5;129;01min\u001b[39;00m data_religion_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      5\u001b[0m     data_group \u001b[38;5;241m=\u001b[39m data_religion_dict[group_cat]\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importance_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumerical_feature_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_label_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_cat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_cat\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fang/ML-Poli-Sci/code/utils.py:388\u001b[0m, in \u001b[0;36mfeature_importance_analysis\u001b[0;34m(data_group, numerical_feature_list, categorical_feature_list, target_variable, value_label_dict, folder_name, group, group_cat)\u001b[0m\n\u001b[1;32m    384\u001b[0m X_continuous_categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((X_continuous_transformed, X_categorical_transformed), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    386\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(l1_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m, max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m, solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m, penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 388\u001b[0m accuracy_list, recall_list, precision_list, f1_list, roc_auc_list, importance_list \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_continuous_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# use imbalanced learn to deal with the imbalanced data\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# accuracy_list, recall_list, precision_list, f1_list, roc_auc_list, importance_list = utils.cross_validation_imb(X_continuous_categorical, Y_target, model, k = 5)\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage accuracy: \u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(accuracy_list))\n",
      "File \u001b[0;32m~/fang/ML-Poli-Sci/code/utils.py:302\u001b[0m, in \u001b[0;36mcross_validation\u001b[0;34m(X, Y, model, k)\u001b[0m\n\u001b[1;32m    300\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m X[train_index], X[test_index]\n\u001b[1;32m    301\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m Y[train_index], Y[test_index]\n\u001b[0;32m--> 302\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m    304\u001b[0m accuracy_list\u001b[38;5;241m.\u001b[39mappend(accuracy_score(y_test, y_pred))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1246\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1244\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1250\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1251\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1254\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "group = 'religon'\n",
    "\n",
    "for group_cat in data_religion_dict.keys():\n",
    "\n",
    "    data_group = data_religion_dict[group_cat]\n",
    "\n",
    "    utils.feature_importance_analysis(data_group, numerical_feature_list, categorical_feature_list, target_variable, value_label_dict, folder_name, group=group, group_cat=group_cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1.13_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
