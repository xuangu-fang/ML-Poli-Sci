{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Prediction Model for Non-voter-Group\n",
    "\n",
    "- Idea 1: train model on voter-group, predict on non-voter-group\n",
    "- Idea 2: use transfer learning (TCA), to apply the feature transformation, then train model on voter-group, predict on non-voter-group\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020.0\n",
      "1948.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "# import model\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# data path\n",
    "file_path = '../data/cumulative_2022_v3_9_domain.csv'\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "column_to_variable_dict = np.load('../data/column_to_variable_dict.npy', allow_pickle=True).item()\n",
    "variable_to_column_dict = np.load('../data/variable_to_column_dict.npy', allow_pickle=True).item()\n",
    "\n",
    "value_label_dict = np.load('../data/value_labels.npy', allow_pickle=True).item()\n",
    "\n",
    "# check the \"Year\" column's max and min value\n",
    "print(data['Year'].max())\n",
    "print(data['Year'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples who vote Democrat :  16419\n",
      "number of samples who vote Republican:  14526\n",
      "number of samples who vote case DK :  0\n",
      "number of samples who do not vote :  17790\n",
      "number of samples who do vote D or R :  30945\n"
     ]
    }
   ],
   "source": [
    "target_variable = 'Voted_D_R'\n",
    "\n",
    "'''Voted_D_R  {0.0: '0. Did not vote; DK/NA if voted; refused to say if', 1.0: '1. Democrat', 2.0: '2. Republican'}'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_train = data[(data['Voted_D_R'] == 1) | (data['Voted_D_R'] == 2)]\n",
    "data_test = data[data['Voted'] == 1]\n",
    "\n",
    "data_new = pd.concat([data_train, data_test])\n",
    "\n",
    "print('number of samples who vote Democrat : ', len(data_new[data_new[target_variable] == 1]))\n",
    "print('number of samples who vote Republican: ', len(data_new[data_new[target_variable] == 2]))\n",
    "print('number of samples who vote case DK : ', len(data_new[data_new[target_variable] == 0]))\n",
    "print('number of samples who do not vote : ', len(data_test))\n",
    "print('number of samples who do vote D or R : ', len(data_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value = utils.missing_value_analysis(data_new)\n",
    "\n",
    "# threshold_list = [0.2, 0.3, 0.4, 0.5]\n",
    "threshold_list = [0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "\n",
    "# must_include_list = ['urbanism']\n",
    "must_include_list = None\n",
    "\n",
    "\n",
    "folder_name = '../data/universal_predict/'\n",
    "\n",
    "used_features, not_used_features, folder_name = utils.feature_filter(data_new, threshold_list,column_to_variable_dict, folder_name, must_include_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21348, 119)\n",
      "(9809, 119)\n",
      "(31157, 119)\n",
      "number of numerical features:  11\n",
      "number of categorical features:  48\n",
      "numerical features list: ['therm_Christians', 'therm_Mislims', 'therm_ChrFundament', 'therm_hispanics', 'therm_RepParty', 'therm_DemParty', 'therm_Whites', 'therm_liberals', 'therm_conservatives', 'therm_Blacks', 'Age']\n"
     ]
    }
   ],
   "source": [
    "# use the used features to filter out the data\n",
    "\n",
    "# set the target variable set and index variable set, these variables will not be used for training\n",
    "\n",
    "target_variable_list = ['Voted','Registered_voted','Voted_party','Vote_Nonvote_Pres','Voted_D_R']\n",
    "\n",
    "race_variable_list = ['Race3','Race4','Race7']\n",
    "\n",
    "religion_variable_list = ['religion']\n",
    "\n",
    "index_variable_list = ['Year', ]\n",
    "\n",
    "not_used_features = ['Pre_election_inten_vote']\n",
    "# not_used_features = []\n",
    "\n",
    "\n",
    "state_variable_list = ['State']\n",
    "\n",
    "non_feature_list = target_variable_list +  race_variable_list + religion_variable_list + index_variable_list + not_used_features + state_variable_list\n",
    "\n",
    "year_threshold = 1982\n",
    "\n",
    "folder_name = folder_name + '/'+ str(year_threshold)+ '/'\n",
    "\n",
    "# filter out the samples whose year > year_threshold\n",
    "data_train = data_train[data_train['Year'] > year_threshold]\n",
    "data_test = data_test[data_test['Year'] > year_threshold]\n",
    "\n",
    "data_new = pd.concat([data_train, data_test]).reset_index(drop=True)\n",
    "\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n",
    "print(data_new.shape)\n",
    "\n",
    "\n",
    "numerical_feature_list, categorical_feature_list = utils.feature_type_analysis(data_new, used_features, non_feature_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31157, 60)\n",
      "average accuracy:  0.9270187062878559\n",
      "average recall:  0.9350664489219414\n",
      "average precision:  0.9344787175531423\n",
      "average f1 score:  0.93473250813851\n",
      "average roc auc score:  0.9260400980063377\n",
      "1    5722\n",
      "0    4087\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_variable = 'Voted_D_R'\n",
    "\n",
    "utils.universal_predict(data_train,data_test, numerical_feature_list, categorical_feature_list, target_variable, value_label_dict, folder_name, group='', group_cat='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/universal_predict/_threshold_10_0.2_threshold_20_0.3_threshold_30_0.4_threshold_40_0.5/1982/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def universal_predict_TCA(data_source,data_target, numerical_feature_list, categorical_feature_list, target_variable, value_label_dict, folder_name, group='', group_cat=''):\n",
    "\n",
    "    # apply transfer component analysis (TCA) to the data\n",
    "\n",
    "     \n",
    "    N1 = len(data_source)\n",
    "    N2 = len(data_target)\n",
    "\n",
    "    data_group = pd.concat([data_source, data_target]).reset_index(drop=True)\n",
    "\n",
    "    X_categorical_transformed, X_continuous_transformed, Y_target, enc_categorical_feature_list = utils.feature_process(data_group, numerical_feature_list, categorical_feature_list, target_variable,value_label_dict)\n",
    "\n",
    "    X_continuous_categorical = np.concatenate((X_continuous_transformed, X_categorical_transformed), axis=1)\n",
    "\n",
    "    # only use the source data to train the model\n",
    "    Y_target_train = Y_target[:N1]\n",
    "\n",
    "    X_continuous_categorical_train = X_continuous_categorical[:N1]\n",
    "\n",
    "    X_continuous_categorical_test = X_continuous_categorical[N1:]\n",
    "\n",
    "\n",
    "\n",
    "    model = LogisticRegression(l1_ratio = 0.5, max_iter = 500, solver = 'saga', penalty = 'elasticnet')\n",
    "\n",
    "    accuracy_list, recall_list, precision_list, f1_list, roc_auc_list, importance_list = utils.cross_validation(X_continuous_categorical_train, Y_target_train, model, k = 5)\n",
    "\n",
    "    # use imbalanced learn to deal with the imbalanced data\n",
    "    # accuracy_list, recall_list, precision_list, f1_list, roc_auc_list, importance_list = utils.cross_validation_imb(X_continuous_categorical, Y_target, model, k = 5)\n",
    "\n",
    "\n",
    "    print('average accuracy: ', np.mean(accuracy_list))\n",
    "    print('average recall: ', np.mean(recall_list))\n",
    "    print('average precision: ', np.mean(precision_list))\n",
    "    print('average f1 score: ', np.mean(f1_list))\n",
    "    print('average roc auc score: ', np.mean(roc_auc_list))\n",
    "\n",
    "    # build the feature importance dataframe\n",
    "    feature_importance = pd.DataFrame({'feature': numerical_feature_list + enc_categorical_feature_list, 'importance': np.mean(importance_list, axis=0)})\n",
    "\n",
    "     # further process the feature importance dataframe, drop the features whose name includes {DK', 'NA', 'RF', 'Missing'}\n",
    "    feature_importance_effect = feature_importance[~feature_importance['feature'].str.contains('DK|NA|RF|Missing')]\n",
    "\n",
    "\n",
    "    top_15_positive = feature_importance_effect.sort_values('importance', ascending = False).head(15)\n",
    "    top_15_negative = feature_importance_effect.sort_values('importance', ascending = True).head(15)\n",
    "\n",
    "    # build a folder to save the results\n",
    "\n",
    "    if group_cat == '':\n",
    "        sub_folder_name = folder_name + group + '/'\n",
    "    else:\n",
    "        sub_folder_name = folder_name + group + '/' + group_cat + '/' \n",
    "    \n",
    "    if not os.path.exists(sub_folder_name):\n",
    "        os.makedirs(sub_folder_name)\n",
    "\n",
    "    # recall: the non-voter are the positive samples, the voter are the negative samples\n",
    "\n",
    "    feature_importance.to_csv(sub_folder_name + 'feature_importance_full.csv', index = False)\n",
    "    feature_importance_effect.to_csv(sub_folder_name + 'feature_importance_effect.csv', index = False)\n",
    "    top_15_positive.to_csv(sub_folder_name + 'top_15_Demo.csv', index = False)\n",
    "    top_15_negative.to_csv(sub_folder_name + 'top_15_Repub.csv', index = False)\n",
    "\n",
    "    # add the ratio of the positive samples(non-voter) in the group\n",
    "    non_voter_ratio = len(data_group[data_group[target_variable] == 1]) / len(data_group)\n",
    "\n",
    "    # save the mean of the metrics\n",
    "    metrics = pd.DataFrame({ 'non-voter-ratio': non_voter_ratio ,   'accuracy': np.mean(accuracy_list), 'recall': np.mean(recall_list), 'precision': np.mean(precision_list), 'f1': np.mean(f1_list), 'roc_auc': np.mean(roc_auc_list)}, index = [0])\n",
    "    metrics.to_csv(sub_folder_name + 'metrics.csv', index = False)\n",
    "\n",
    "\n",
    "    #  apply the universal model to the target data\n",
    "    model.fit(X_continuous_categorical_train, Y_target_train)\n",
    "    Y_target_predict = model.predict(X_continuous_categorical_test)\n",
    "\n",
    "    # value counts of the prediction\n",
    "    print(pd.Series(Y_target_predict).value_counts())\n",
    "\n",
    "    # save the prediction results as a csv file\n",
    "    data_target['prediction'] = Y_target_predict\n",
    "    data_target.to_csv(sub_folder_name + 'prediction.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1.13_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
