{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "count the missing values of each dommain features, set the threshold to 0.3 to filter out the features with too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020.0\n",
      "1948.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# data path\n",
    "file_path = '../data/cumulative_2022_v3_9_domain.csv'\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "column_to_variable_dict = np.load('../data/column_to_variable_dict.npy', allow_pickle=True).item()\n",
    "variable_to_column_dict = np.load('../data/variable_to_column_dict.npy', allow_pickle=True).item()\n",
    "\n",
    "# check the \"Year\" column's max and min value\n",
    "print(data['Year'].max())\n",
    "print(data['Year'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                                  0\n",
       "South                              1801\n",
       "region                             1801\n",
       "racial_composition_nbhood         59420\n",
       "racial_composition_gradeSchool    60327\n",
       "                                  ...  \n",
       "occupation                        28223\n",
       "occupation14                      51795\n",
       "occupation71                      51795\n",
       "home_ownership                    13672\n",
       "urbanism                          24972\n",
       "Length: 116, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis the missing value of each column in differernt period:\n",
    "# 1. overall missing value and percentage\n",
    "# 2. missing value and percentage in recent 10 years (\"Year\" >= 2012)\")\n",
    "# 3. missing value and percentage in recent 20 years (\"Year\" >= 2002)\")\n",
    "# 4. missing value and percentage in recent 30 years (\"Year\" >= 1992)\")\n",
    "# 5. missing value and percentage in recent 40 years (\"Year\" >= 1982)\")\n",
    "# 6. missing value and percentage in recent 50 years (\"Year\" >= 1972)\")\n",
    "# 7. missing value and percentage in recent 60 years (\"Year\" >= 1962)\")\n",
    "\n",
    "# save the result in csv file, the first column is the feature name\n",
    "\n",
    "\n",
    "def missing_value_analysis(data):\n",
    "    # get the number of missing value of each column\n",
    "    missing_value_num = data.isnull().sum()\n",
    "    # get the percentage of missing value of each column\n",
    "    missing_value_percentage = missing_value_num / len(data)\n",
    "\n",
    "    missing_value_percentage_10 = data[data['Year'] >= 2012].isnull().sum() / len(data[data['Year'] >= 2012])\n",
    "    missing_value_percentage_20 = data[data['Year'] >= 2002].isnull().sum() / len(data[data['Year'] >= 2002])\n",
    "    missing_value_percentage_30 = data[data['Year'] >= 1992].isnull().sum() / len(data[data['Year'] >= 1992])\n",
    "    missing_value_percentage_40 = data[data['Year'] >= 1982].isnull().sum() / len(data[data['Year'] >= 1982])\n",
    "    missing_value_percentage_50 = data[data['Year'] >= 1972].isnull().sum() / len(data[data['Year'] >= 1972])\n",
    "    missing_value_percentage_60 = data[data['Year'] >= 1962].isnull().sum() / len(data[data['Year'] >= 1962])\n",
    "    missing_value_percentage_70 = data[data['Year'] >= 1952].isnull().sum() / len(data[data['Year'] >= 1952])\n",
    "\n",
    "    # get the variable name of each column by using the column_to_variable_dict\n",
    "    # missing_value_num.index = column_to_variable_dict['variable']\n",
    "\n",
    "\n",
    "    # combine the result\n",
    "    missing_value = pd.concat([missing_value_num, missing_value_percentage,\n",
    "                               missing_value_percentage_10, missing_value_percentage_20,\n",
    "                               missing_value_percentage_30, missing_value_percentage_40,\n",
    "                               missing_value_percentage_50, missing_value_percentage_60,    missing_value_percentage_70], axis=1)\n",
    "    missing_value.columns = ['missing_value_num', 'missing_value_percentage',\n",
    "                                'missing_value_percentage_10(>=2012)', 'missing_value_percentage_20(>=2002)',\n",
    "                                'missing_value_percentage_30(>=1992)', 'missing_value_percentage_40(>=1982)',\n",
    "                                'missing_value_percentage_50(>=1972)', 'missing_value_percentage_60(>=1962)', 'missing_value_percentage_60(>=1952)']\n",
    "\n",
    "    # sort the result by missing value percentage\n",
    "    missing_value = missing_value.sort_values(by='missing_value_percentage', ascending=False)\n",
    "\n",
    "\n",
    "    return missing_value\n",
    "\n",
    "missing_value = missing_value_analysis(data)\n",
    "\n",
    "# save the result\n",
    "# massing_value.to_csv('../data/missing_value_analysis.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one column to indicate the variable name of each row,using the index of the missing_value as the key\n",
    "\n",
    "variable_name = [ column_to_variable_dict[var] for var in missing_value.index]\n",
    "missing_value['variable_name'] = variable_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features used:  72\n",
      "number of features not used:  44\n"
     ]
    }
   ],
   "source": [
    "# set the filter-out thresholds:\n",
    "# 1. missing_value_percentage_10(>=2012) < 0.3\n",
    "# 2. missing_value_percentage_20(>=2002) < 0.4\n",
    "# 3. missing_value_percentage_30(>=1992) < 0.5\n",
    "\n",
    "threshold_10 = 0.3\n",
    "threshold_20 = 0.4\n",
    "threshold_30 = 0.5\n",
    "\n",
    "\n",
    "# filter out the features\n",
    "missing_value_used = missing_value[(\n",
    "                missing_value['missing_value_percentage_10(>=2012)'] < threshold_10) & \n",
    "                                        (missing_value['missing_value_percentage_20(>=2002)'] < threshold_20) &\n",
    "                                        (missing_value['missing_value_percentage_30(>=1992)'] < threshold_30)]\n",
    "\n",
    "missing_value_not_used = missing_value[(\n",
    "                missing_value['missing_value_percentage_10(>=2012)'] >= threshold_10) | \n",
    "                                        (missing_value['missing_value_percentage_20(>=2002)'] >= threshold_20) |\n",
    "                                        (missing_value['missing_value_percentage_30(>=1992)'] >= threshold_30)]\n",
    "\n",
    "# count the number of features\n",
    "print('number of features used: ', len(missing_value_used))\n",
    "print('number of features not used: ', len(missing_value_not_used))\n",
    "\n",
    "# save the result\n",
    "# make folder namsed with threshold:\n",
    "folder_name = '../data/threshold_10_' + str(threshold_10) + '_threshold_20_' + str(threshold_20) + '_threshold_30_' + str(threshold_30)\n",
    "\n",
    "# make folder if not exist\n",
    "import os\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "missing_value_used.to_csv(folder_name + '/missing_value_analysis_used.csv')\n",
    "missing_value_not_used.to_csv(folder_name + '/missing_value_analysis_not_used.csv')\n",
    "\n",
    "# save the used features names (row names) and the variable names\n",
    "used_features = missing_value_used.index.tolist()\n",
    "with open(folder_name + '/used_features.txt', 'w') as f:\n",
    "    for item in used_features:\n",
    "        f.write(\"%s (%s)\\n\" % (item, column_to_variable_dict[item]))\n",
    "\n",
    "# save the not used features names (row names)\n",
    "not_used_features = missing_value_not_used.index.tolist()\n",
    "with open(folder_name + '/not_used_features.txt', 'w') as f:\n",
    "    for item in not_used_features:\n",
    "        f.write(\"%s (%s)\\n\" % (item, column_to_variable_dict[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing value of the target variable: \n",
      "Voted                0.091551\n",
      "Registered_voted     0.218061\n",
      "Voted_party          0.536483\n",
      "Vote_Nonvote_Pres    0.377067\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# use the used features to filter out the data\n",
    "\n",
    "# set the target variable set and index variable set, these variables will not be used for training\n",
    "\n",
    "target_variable_list = ['Voted','Registered_voted','Voted_party','Vote_Nonvote_Pres']\n",
    "\n",
    "index_variable_list = ['Year', ]\n",
    "\n",
    "# check the missing ratio of the target variable\n",
    "print('missing value of the target variable: ')\n",
    "print(data[target_variable_list].isnull().sum() / len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples who not vote :  17790\n",
      "number of samples who vote :  44188\n",
      "number of samples who vote case DK :  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(61978, 116)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_variable = 'Voted'\n",
    "\n",
    "'''Voted  {0.0: '0. DK; NA; no Post IW; refused to say if voted;', 1.0: '1. No, did not vote', 2.0: '2. Yes, voted'}'''\n",
    "\n",
    "# filter out the samples with missing value of the target variable,drop the index\n",
    "data_new = data[data[target_variable].notnull()]\n",
    "# filter out the samples with target variable value = 0, count the number of samples whose target variable value = 0, 1 or 2\n",
    "print('number of samples who not vote : ', len(data_new[data_new[target_variable] == 1]))\n",
    "print('number of samples who vote : ', len(data_new[data_new[target_variable] == 2]))\n",
    "print('number of samples who vote case DK : ', len(data_new[data_new[target_variable] == 0]))\n",
    "\n",
    "data_new = data_new[data_new[target_variable] != 0]\n",
    "data_new = data_new.reset_index(drop=True)\n",
    "data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# delete the target variable from the used features\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mused_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_variable_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# further filter out the samples with missing value of the used features\u001b[39;00m\n\u001b[1;32m      9\u001b[0m data_new \u001b[38;5;241m=\u001b[39m data_new[used_features]\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "# delete the target variable from the used features\n",
    "# used_features.remove(target_variable_set)\n",
    "\n",
    "\n",
    "# further filter out the samples with missing value of the used features\n",
    "\n",
    "\n",
    "\n",
    "data_new = data_new[used_features]\n",
    "data_new = data_new[data_new.notnull().all(axis=1)]\n",
    "data_new = data_new.reset_index(drop=True)\n",
    "data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blackInfluence_Politics',\n",
       " 'powerDifference',\n",
       " 'votingMakedifference',\n",
       " 'bisexalFamilyorFriends',\n",
       " 'therm_Christians',\n",
       " 'satisfactionDemocracy',\n",
       " 'follow_political_info',\n",
       " 'howOftenTrust',\n",
       " 'therm_Mislims',\n",
       " 'sex_orientation',\n",
       " 'satisfactionLife',\n",
       " 'living_withFamily',\n",
       " 'meetingCommuntySchool',\n",
       " 'workedWithcommunity',\n",
       " 'VCF9022',\n",
       " 'authoritarian2',\n",
       " 'authoritarian4',\n",
       " 'authoritarian1',\n",
       " 'authoritarian3',\n",
       " 'have_healthInsurance',\n",
       " 'volunteer',\n",
       " 'bornAgain',\n",
       " 'therm_ChrFundament',\n",
       " 'VCF0886',\n",
       " 'church_attendance',\n",
       " 'Voted_party',\n",
       " 'therm_hispanics',\n",
       " 'VCF9029',\n",
       " 'VCF0890',\n",
       " 'VCF9031',\n",
       " 'VCF9028',\n",
       " 'approve_president_economy',\n",
       " 'Vote_Nonvote_Pres',\n",
       " 'approve_pres_strength',\n",
       " 'therm_RepParty',\n",
       " 'therm_DemParty',\n",
       " 'Pre_election_inten_vote',\n",
       " 'therm_Whites',\n",
       " 'Will_PresElectionClose',\n",
       " 'therm_liberals',\n",
       " 'therm_conservatives',\n",
       " 'therm_Blacks',\n",
       " 'ideology7',\n",
       " 'approve_pres',\n",
       " 'VCF9030c',\n",
       " 'VCF9030b',\n",
       " 'Registered_voted',\n",
       " 'VCF9030a',\n",
       " 'VCF0130',\n",
       " 'VCF9030',\n",
       " 'home_ownership',\n",
       " 'VCF0720',\n",
       " 'VCF0721',\n",
       " 'VCF0719',\n",
       " 'VCF0718',\n",
       " 'VCF0717',\n",
       " 'Family_income',\n",
       " 'Interest_elections',\n",
       " 'Age',\n",
       " 'region',\n",
       " 'South',\n",
       " 'Party_id3',\n",
       " 'Party_id7',\n",
       " 'Race4',\n",
       " 'Race3',\n",
       " 'Race7',\n",
       " 'education6',\n",
       " 'education7',\n",
       " 'Education4',\n",
       " 'Gender',\n",
       " 'Year']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1.13_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
